# -*- coding: utf-8 -*-
"""ML_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eves9Udm_C87tce2dwl2rbyAyXDkOawg
"""

import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from numpy import linalg

iris_data = datasets.load_iris()
X = iris_data['data']
X = X[:][:100]
Y = iris_data['target']
Y = Y[:100]
comparison_value = 6.75
print(X.shape)
print(Y.shape)

class SVM:
    def __init__(self, learning_rate=0.001, lambda_param=0.01, epochs=1000):
        self.learning_rate = learning_rate
        self.num_iterations = epochs
        self.lambda_ = lambda_param
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        n_samples, n_features = X.shape

        self.weights = np.zeros(n_features)
        self.bias = 0

        for _ in range(self.num_iterations):
            for i in range(n_samples):
                output = self._predict(X[i])
                if y[i] * output <= 1: # It means that the classification is wrong
                    self.weights += self.learning_rate * (y[i] * X[i] - 2 * self.lambda_ * self.weights)
                    # self.weights += self.learning_rate * (y[i] * X[i] - 2 * self.weights)
                    self.bias += self.learning_rate * y[i]
                else: # it means that the classification is correct
                    self.weights -= self.learning_rate * (2 * self.lambda_ * self.weights)
                    # self.weights -= self.learning_rate * (2 * self.weights)

    def predict(self, X):
        y_pred = []
        for i in range(X.shape[0]):
            output = self._predict(X[i])
            if output > 1:
                y_pred.append(1)
            else:
                y_pred.append(0)
        return y_pred

    def get_alpha(self, X, y):
        # Number of samples
        n_samples = len(X)
        # Initialize alpha values to zeros
        alpha = np.zeros(n_samples)
        # Linear combination
        linear_model = np.dot(X, self.weights) + self.bias
        # Errors
        errors = y - linear_model
        # Calculate alpha values
        for i in range(n_samples):
            alpha[i] = errors[i] / (1 - self.lambda_ * np.dot(X[i], X[i]))
        return alpha

    def _predict(self, x):
        return np.dot(self.weights, x) + self.bias

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

from sklearn.svm import SVC
svc = SVC()
svc.fit(x_train, y_train)

model = SVM(learning_rate=0.0005, epochs=10000)
model.fit(x_train, y_train)

# use accuracy score to calculate the accuracy after precicting the outpus
y_hat = model.predict(x_test)
scores = accuracy_score(y_test, y_hat)

# the generalization error is the average of the scores
generalization_error = 1 - np.mean(scores)
print('Scores: ' + str(scores))
print('Generlizaiton Error: ' + str(generalization_error))

# calculate alpha
alpha = model.get_alpha(x_train, y_train)
print(alpha)

def visualize_svm():
        def get_hyperplane_value(x, w, b, offset):
            return (-w[2] * x + b + offset) / w[3]

        fig = plt.figure()
        ax = fig.add_subplot(1, 1, 1)
        plt.scatter(X[:, 2], X[:, 3], marker="o", c=Y)

        x0_1 = np.amin(X[:, 2])
        x0_2 = np.amax(X[:, 2])

        x1_1 = get_hyperplane_value(x0_1, model.weights, model.bias, 0)
        x1_2 = get_hyperplane_value(x0_2, model.weights, model.bias, 0)

        x1_1_m = get_hyperplane_value(x0_1, model.weights, model.bias, -1)
        x1_2_m = get_hyperplane_value(x0_2, model.weights, model.bias, -1)

        x1_1_p = get_hyperplane_value(x0_1, model.weights, model.bias, 1)
        x1_2_p = get_hyperplane_value(x0_2, model.weights, model.bias, 1)

        ax.plot([x0_1, x0_2], [x1_1, x1_2], "y--")
        ax.plot([x0_1, x0_2], [x1_1_m, x1_2_m], "k")
        ax.plot([x0_1, x0_2], [x1_1_p, x1_2_p], "k")

        x1_min = np.amin(X[:, 3])
        x1_max = np.amax(X[:, 3])
        ax.set_ylim([x1_min - 3, x1_max + 3])

        plt.show()

visualize_svm()

# VC Dimension
vc = svc.support_vectors_.shape[0]
print(vc)

w_norm = linalg.norm(model.weights)

# Initialize a list to store the support vectors
support_vectors = []

# Iterate over the training examples
for i, x in enumerate(X):
  # Calculate the distance of x from the decision boundary
  distance = abs(model.weights.dot(x) + model.bias) / w_norm
  
  # If x is a support vector, add it to the list
  if distance < comparison_value:
    support_vectors.append(x)

# Calculate the number of support vectors
vc = len(support_vectors)
print(vc)

